{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3fd5781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\n",
      "Output VJEPA: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\preprocessed_vjepa\n",
      "Output E2T: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\preprocessed_e2t\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Configuration\n",
    "TRAIN_SUBJECTS = ['ZAB', 'ZDM', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW','ZDN',]\n",
    "VAL_SUBJECTS = ['ZMG']\n",
    "TEST_SUBJECTS = ['ZPH']\n",
    "\n",
    "# Paths - Update these to match your setup\n",
    "BASE_DIR = Path(r\"c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\")\n",
    "PICKLE_DIR = BASE_DIR / \"src\" / \"datasets\" / \"ZuCo\"\n",
    "\n",
    "# Pickle file paths\n",
    "PICKLE_FILES = {\n",
    "    'task1-SR': PICKLE_DIR / \"task1-SR\" / \"pickle\" / \"task1-SR-dataset-spectro.pickle\",\n",
    "    'task2-NR': PICKLE_DIR / \"task2-NR\" / \"pickle\" / \"task2-NR-dataset-spectro.pickle\",\n",
    "    'task3-TSR': PICKLE_DIR / \"task3-TSR\" / \"pickle\" / \"task3-TSR-dataset-spectro.pickle\",\n",
    "}\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR_VJEPA = BASE_DIR / \"src\" / \"datasets\" / \"preprocessed_vjepa\"\n",
    "OUTPUT_DIR_E2T = BASE_DIR / \"src\" / \"datasets\" / \"preprocessed_e2t\"\n",
    "\n",
    "# EEG-VJEPA preprocessing parameters\n",
    "TIME_WINDOW = 512  # ~1 sec at 500 Hz\n",
    "N_FFT = 64\n",
    "HOP_LENGTH = 16\n",
    "OVERLAP = 0.5  # 50% overlap between windows\n",
    "\n",
    "# EEG-to-Text preprocessing parameters\n",
    "MAX_EEG_LENGTH = 8000  # Maximum EEG sequence length (pad/truncate)\n",
    "TARGET_CHANNELS = 105  # Expected number of EEG channels\n",
    "\n",
    "print(f\"Base Directory: {BASE_DIR}\")\n",
    "print(f\"Output VJEPA: {OUTPUT_DIR_VJEPA}\")\n",
    "print(f\"Output E2T: {OUTPUT_DIR_E2T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c5956",
   "metadata": {},
   "source": [
    "<!-- # ## 2. Load & Explore Pickle Files -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d0ddea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\n",
      "Output VJEPA: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\preprocessed_vjepa_subjects\n",
      "Output E2T: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\preprocessed_e2t_subjects\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 1. Imports & Configuration\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Configuration\n",
    "TRAIN_SUBJECTS = ['ZAB', 'ZDM', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW',]\n",
    "VAL_SUBJECTS = ['ZMG']\n",
    "TEST_SUBJECTS = ['ZPH']\n",
    "ALL_SUBJECTS = TRAIN_SUBJECTS + VAL_SUBJECTS + TEST_SUBJECTS\n",
    "\n",
    "# Paths - Update these to match your setup\n",
    "BASE_DIR = Path(r\"c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\")\n",
    "PICKLE_DIR = BASE_DIR / \"src\" / \"datasets\" / \"ZuCo\"\n",
    "\n",
    "# Pickle file paths\n",
    "PICKLE_FILES = {\n",
    "    'task1-SR': PICKLE_DIR / \"task1-SR\" / \"pickle\" / \"task1-SR-dataset-spectro.pickle\",\n",
    "    'task2-NR': PICKLE_DIR / \"task2-NR\" / \"pickle\" / \"task2-NR-dataset-spectro.pickle\",\n",
    "    'task3-TSR': PICKLE_DIR / \"task3-TSR\" / \"pickle\" / \"task3-TSR-dataset-spectro.pickle\",\n",
    "}\n",
    "\n",
    "# Output directories  \n",
    "OUTPUT_DIR_VJEPA = BASE_DIR / \"src\" / \"datasets\" / \"preprocessed_vjepa_subjects\"\n",
    "OUTPUT_DIR_E2T = BASE_DIR / \"src\" / \"datasets\" / \"preprocessed_e2t_subjects\"\n",
    "\n",
    "# EEG-VJEPA preprocessing parameters\n",
    "TIME_WINDOW = 512  # ~1 sec at 500 Hz\n",
    "N_FFT = 64\n",
    "HOP_LENGTH = 16\n",
    "OVERLAP = 0.5  # 50% overlap between windows\n",
    "\n",
    "# EEG-to-Text preprocessing parameters\n",
    "MAX_EEG_LENGTH = 8000  # Maximum EEG sequence length (pad/truncate)\n",
    "TARGET_CHANNELS = 105  # Expected number of EEG channels\n",
    "\n",
    "print(f\"Base Directory: {BASE_DIR}\")\n",
    "print(f\"Output VJEPA: {OUTPUT_DIR_VJEPA}\")\n",
    "print(f\"Output E2T: {OUTPUT_DIR_E2T}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e993a3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\ZuCo\\task1-SR\\pickle\\task1-SR-dataset-spectro.pickle\n",
      "\n",
      "============================================================\n",
      "Exploring: task1-SR\n",
      "============================================================\n",
      "Subjects (12): ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "  ZAB: 392 valid sentences\n",
      "  ZDM: 384 valid sentences\n",
      "  ZDN: 294 valid sentences\n",
      "  ZGW: 376 valid sentences\n",
      "  ZJM: 400 valid sentences\n",
      "  ZJN: 384 valid sentences\n",
      "  ZJS: 338 valid sentences\n",
      "  ZKB: 399 valid sentences\n",
      "  ZKH: 392 valid sentences\n",
      "  ZKW: 399 valid sentences\n",
      "  ZMG: 386 valid sentences\n",
      "  ZPH: 393 valid sentences\n",
      "\n",
      "Data Statistics:\n",
      "  Channels: {105}\n",
      "  Time range: [39, 14819]\n",
      "  Mean length: 2783.2\n",
      "  Total valid samples: 4537\n",
      "Loading: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\ZuCo\\task2-NR\\pickle\\task2-NR-dataset-spectro.pickle\n",
      "\n",
      "============================================================\n",
      "Exploring: task2-NR\n",
      "============================================================\n",
      "Subjects (12): ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "  ZAB: 295 valid sentences\n",
      "  ZDM: 292 valid sentences\n",
      "  ZDN: 298 valid sentences\n",
      "  ZGW: 281 valid sentences\n",
      "  ZJM: 258 valid sentences\n",
      "  ZJN: 294 valid sentences\n",
      "  ZJS: 217 valid sentences\n",
      "  ZKB: 297 valid sentences\n",
      "  ZKH: 294 valid sentences\n",
      "  ZKW: 296 valid sentences\n",
      "  ZMG: 287 valid sentences\n",
      "  ZPH: 247 valid sentences\n",
      "\n",
      "Data Statistics:\n",
      "  Channels: {105}\n",
      "  Time range: [15, 23630]\n",
      "  Mean length: 3611.7\n",
      "  Total valid samples: 3356\n",
      "Loading: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\ZuCo\\task3-TSR\\pickle\\task3-TSR-dataset-spectro.pickle\n",
      "\n",
      "============================================================\n",
      "Exploring: task3-TSR\n",
      "============================================================\n",
      "Subjects (12): ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "  ZAB: 388 valid sentences\n",
      "  ZDM: 397 valid sentences\n",
      "  ZDN: 406 valid sentences\n",
      "  ZGW: 352 valid sentences\n",
      "  ZJM: 407 valid sentences\n",
      "  ZJN: 397 valid sentences\n",
      "  ZJS: 362 valid sentences\n",
      "  ZKB: 359 valid sentences\n",
      "  ZKH: 381 valid sentences\n",
      "  ZKW: 407 valid sentences\n",
      "  ZMG: 404 valid sentences\n",
      "  ZPH: 317 valid sentences\n",
      "\n",
      "Data Statistics:\n",
      "  Channels: {105}\n",
      "  Time range: [28, 22727]\n",
      "  Mean length: 2137.6\n",
      "  Total valid samples: 4577\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Load & Explore Pickle Files\n",
    "\n",
    "# %%\n",
    "def load_pickle_data(pickle_path: Path) -> Dict:\n",
    "    \"\"\"Load a pickle file and return the data.\"\"\"\n",
    "    print(f\"Loading: {pickle_path}\")\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def explore_pickle_data(data: Dict, task_name: str):\n",
    "    \"\"\"Explore the structure of a pickle file.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Exploring: {task_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    subjects = list(data.keys())\n",
    "    print(f\"Subjects ({len(subjects)}): {subjects}\")\n",
    "    \n",
    "    total_samples = 0\n",
    "    sample_shapes = []\n",
    "    \n",
    "    for subj in subjects:\n",
    "        valid_count = 0\n",
    "        for sent in data[subj]:\n",
    "            if sent is not None:\n",
    "                valid_count += 1\n",
    "                total_samples += 1\n",
    "                raw = sent['sentence_level_EEG']['rawData']\n",
    "                sample_shapes.append(raw.shape)\n",
    "        print(f\"  {subj}: {valid_count} valid sentences\")\n",
    "    \n",
    "    if sample_shapes:\n",
    "        channels = set(s[0] for s in sample_shapes)\n",
    "        time_lengths = [s[1] for s in sample_shapes]\n",
    "        print(f\"\\nData Statistics:\")\n",
    "        print(f\"  Channels: {channels}\")\n",
    "        print(f\"  Time range: [{min(time_lengths)}, {max(time_lengths)}]\")\n",
    "        print(f\"  Mean length: {np.mean(time_lengths):.1f}\")\n",
    "        print(f\"  Total valid samples: {total_samples}\")\n",
    "    \n",
    "    return total_samples\n",
    "\n",
    "\n",
    "# Load and explore all pickle files\n",
    "all_data = {}\n",
    "for task_name, pickle_path in PICKLE_FILES.items():\n",
    "    if pickle_path.exists():\n",
    "        all_data[task_name] = load_pickle_data(pickle_path)\n",
    "        explore_pickle_data(all_data[task_name], task_name)\n",
    "    else:\n",
    "        print(f\"⚠ Not found: {pickle_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81723a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 3. EEG-VJEPA Preprocessing Functions\n",
    "\n",
    "# %%\n",
    "def compute_spectrogram(eeg_data: np.ndarray, n_fft: int = 64, hop_length: int = 16) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute STFT spectrogram for each EEG channel.\n",
    "    \"\"\"\n",
    "    n_channels, n_samples = eeg_data.shape\n",
    "    n_freq_bins = n_fft // 2 + 1\n",
    "    n_time_bins = (n_samples - n_fft) // hop_length + 1\n",
    "    \n",
    "    if n_time_bins <= 0:\n",
    "        pad_len = n_fft + hop_length - n_samples\n",
    "        eeg_data = np.pad(eeg_data, ((0, 0), (0, pad_len)), mode='constant')\n",
    "        n_samples = eeg_data.shape[1]\n",
    "        n_time_bins = (n_samples - n_fft) // hop_length + 1\n",
    "    \n",
    "    window = np.hanning(n_fft)\n",
    "    spectrogram = np.zeros((n_channels, n_freq_bins, n_time_bins), dtype=np.float32)\n",
    "    \n",
    "    for ch in range(n_channels):\n",
    "        for t in range(n_time_bins):\n",
    "            start_idx = t * hop_length\n",
    "            segment = eeg_data[ch, start_idx:start_idx + n_fft] * window\n",
    "            fft_result = np.fft.rfft(segment)\n",
    "            spectrogram[ch, :, t] = np.abs(fft_result)\n",
    "    \n",
    "    spectrogram = np.log1p(spectrogram)\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def extract_windows_and_spectrograms(\n",
    "    raw_eeg: np.ndarray,\n",
    "    time_window: int = 512,\n",
    "    overlap: float = 0.5,\n",
    "    n_fft: int = 64,\n",
    "    hop_length: int = 16\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"Extract overlapping time windows and compute spectrograms.\"\"\"\n",
    "    n_channels, n_samples = raw_eeg.shape\n",
    "    step_size = int(time_window * (1 - overlap))\n",
    "    spectrograms = []\n",
    "    \n",
    "    if n_samples < time_window // 2:\n",
    "        return spectrograms\n",
    "    \n",
    "    start = 0\n",
    "    while start + time_window <= n_samples:\n",
    "        window_data = raw_eeg[:, start:start + time_window]\n",
    "        spectrogram = compute_spectrogram(window_data, n_fft, hop_length)\n",
    "        mean = spectrogram.mean(axis=(1, 2), keepdims=True)\n",
    "        std = spectrogram.std(axis=(1, 2), keepdims=True) + 1e-8\n",
    "        spectrogram = (spectrogram - mean) / std\n",
    "        spectrograms.append(spectrogram)\n",
    "        start += step_size\n",
    "    \n",
    "    if n_samples >= time_window and start < n_samples - time_window // 2:\n",
    "        window_data = raw_eeg[:, -time_window:]\n",
    "        spectrogram = compute_spectrogram(window_data, n_fft, hop_length)\n",
    "        mean = spectrogram.mean(axis=(1, 2), keepdims=True)\n",
    "        std = spectrogram.std(axis=(1, 2), keepdims=True) + 1e-8\n",
    "        spectrogram = (spectrogram - mean) / std\n",
    "        spectrograms.append(spectrogram)\n",
    "    \n",
    "    return spectrograms\n",
    "\n",
    "\n",
    "def get_subject_split(subject_id: str) -> str:\n",
    "    \"\"\"Determine which split a subject belongs to.\"\"\"\n",
    "    if subject_id in TRAIN_SUBJECTS:\n",
    "        return 'train'\n",
    "    elif subject_id in VAL_SUBJECTS:\n",
    "        return 'val'\n",
    "    elif subject_id in TEST_SUBJECTS:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deebf690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EEG-VJEPA PREPROCESSING (SUBJECT-BASED)\n",
      "============================================================\n",
      "\n",
      "========================================\n",
      "Processing task1-SR...\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:   8%|▊         | 1/12 [01:11<13:03, 71.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZAB.pt: 3539 samples, 1356.6 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  17%|█▋        | 2/12 [02:49<14:34, 87.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZDM.pt: 3109 samples, 1191.8 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  25%|██▌       | 3/12 [03:32<10:03, 67.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZDN.pt: 2097 samples, 803.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  33%|███▎      | 4/12 [05:04<10:14, 76.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZGW.pt: 4851 samples, 1859.6 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  42%|████▏     | 5/12 [06:14<08:40, 74.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJM.pt: 4647 samples, 1781.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  50%|█████     | 6/12 [08:11<08:53, 88.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJN.pt: 6332 samples, 2427.3 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  58%|█████▊    | 7/12 [08:53<06:06, 73.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJS.pt: 2694 samples, 1032.7 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  67%|██████▋   | 8/12 [09:56<04:40, 70.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKB.pt: 4001 samples, 1533.7 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  75%|███████▌  | 9/12 [10:56<03:20, 66.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKH.pt: 3957 samples, 1516.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  83%|████████▎ | 10/12 [12:35<02:33, 77.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKW.pt: 5216 samples, 1999.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  92%|█████████▏| 11/12 [13:34<01:11, 71.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  val/ZMG.pt: 3116 samples, 1194.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects: 100%|██████████| 12/12 [14:43<00:00, 73.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test/ZPH.pt: 3468 samples, 1329.4 MB\n",
      "\n",
      "========================================\n",
      "Processing task2-NR...\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:   8%|▊         | 1/12 [01:21<14:56, 81.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZAB.pt: 2814 samples, 1078.7 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  17%|█▋        | 2/12 [02:02<09:39, 57.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZDM.pt: 2782 samples, 1066.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  25%|██▌       | 3/12 [02:38<07:10, 47.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZDN.pt: 2229 samples, 854.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  33%|███▎      | 4/12 [03:47<07:29, 56.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZGW.pt: 4296 samples, 1646.8 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  42%|████▏     | 5/12 [04:57<07:06, 60.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJM.pt: 4271 samples, 1637.2 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  50%|█████     | 6/12 [06:39<07:29, 74.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJN.pt: 6338 samples, 2429.6 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  58%|█████▊    | 7/12 [07:08<04:59, 59.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJS.pt: 1663 samples, 637.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  67%|██████▋   | 8/12 [08:42<04:43, 70.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKB.pt: 4743 samples, 1818.2 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  75%|███████▌  | 9/12 [09:55<03:34, 71.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKH.pt: 3549 samples, 1360.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  83%|████████▎ | 10/12 [12:08<03:00, 90.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKW.pt: 6626 samples, 2540.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  92%|█████████▏| 11/12 [13:05<01:20, 80.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  val/ZMG.pt: 2840 samples, 1088.7 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects: 100%|██████████| 12/12 [14:16<00:00, 71.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test/ZPH.pt: 3510 samples, 1345.5 MB\n",
      "\n",
      "========================================\n",
      "Processing task3-TSR...\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects:   8%|▊         | 1/12 [00:52<09:37, 52.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZAB.pt: 2328 samples, 892.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects:  17%|█▋        | 2/12 [01:46<08:55, 53.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZDM.pt: 2367 samples, 907.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects:  25%|██▌       | 3/12 [02:30<07:19, 48.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZDN.pt: 2124 samples, 814.2 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects:  33%|███▎      | 4/12 [03:25<06:50, 51.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZGW.pt: 2689 samples, 1030.8 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects:  42%|████▏     | 5/12 [05:03<07:57, 68.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJM.pt: 4797 samples, 1838.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects:  50%|█████     | 6/12 [06:50<08:08, 81.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJN.pt: 5306 samples, 2034.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects:  58%|█████▊    | 7/12 [07:27<05:34, 66.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJS.pt: 1859 samples, 712.6 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects:  67%|██████▋   | 8/12 [07:58<03:42, 55.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKB.pt: 1522 samples, 583.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects:  75%|███████▌  | 9/12 [09:17<03:08, 62.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKH.pt: 3945 samples, 1512.3 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects:  83%|████████▎ | 10/12 [10:47<02:22, 71.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKW.pt: 4679 samples, 1793.6 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects:  92%|█████████▏| 11/12 [11:34<01:03, 63.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  val/ZMG.pt: 2739 samples, 1050.0 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR subjects: 100%|██████████| 12/12 [11:56<00:00, 59.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test/ZPH.pt: 1493 samples, 572.3 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Process EEG-VJEPA Data (SUBJECT-BASED)\n",
    "\n",
    "# %%\n",
    "def process_vjepa_data_by_subject(all_data: Dict, output_dir: Path):\n",
    "    \"\"\"\n",
    "    Process all pickle data for EEG-VJEPA pretraining.\n",
    "    \n",
    "    Creates SUBJECT-BASED folder structure:\n",
    "    output_dir/\n",
    "    ├── task1-SR/\n",
    "    │   ├── train/\n",
    "    │   │   ├── ZAB.pt      # All spectrograms for subject ZAB\n",
    "    │   │   ├── ZDM.pt\n",
    "    │   │   └── ...\n",
    "    │   ├── val/\n",
    "    │   │   └── ZMG.pt\n",
    "    │   └── test/\n",
    "    │       └── ZPH.pt\n",
    "    ├── task2-NR/\n",
    "    │   └── ...\n",
    "    └── task3-TSR/\n",
    "        └── ...\n",
    "    \n",
    "    Each .pt file contains:\n",
    "        - spectrograms: tensor of shape (N, 1, T, C, F) for this subject\n",
    "        - metadata: list of dicts with sentence_idx, window_idx, task\n",
    "        - subject: subject ID\n",
    "        - split: train/val/test\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EEG-VJEPA PREPROCESSING (SUBJECT-BASED)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    stats = {}\n",
    "    \n",
    "    for task_name, task_data in all_data.items():\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Processing {task_name}...\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        task_dir = output_dir / task_name\n",
    "        \n",
    "        # Create split directories\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            (task_dir / split).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        task_stats = {'train': {}, 'val': {}, 'test': {}}\n",
    "        \n",
    "        for subject_id, sentences in tqdm(task_data.items(), desc=f\"{task_name} subjects\"):\n",
    "            split = get_subject_split(subject_id)\n",
    "            \n",
    "            # Collect all spectrograms for this subject\n",
    "            subject_spectrograms = []\n",
    "            subject_metadata = []\n",
    "            \n",
    "            for sent_idx, sent in enumerate(sentences):\n",
    "                if sent is None:\n",
    "                    continue\n",
    "                \n",
    "                raw_eeg = sent['sentence_level_EEG']['rawData']\n",
    "                \n",
    "                spectrograms = extract_windows_and_spectrograms(\n",
    "                    raw_eeg,\n",
    "                    time_window=TIME_WINDOW,\n",
    "                    overlap=OVERLAP,\n",
    "                    n_fft=N_FFT,\n",
    "                    hop_length=HOP_LENGTH\n",
    "                )\n",
    "                \n",
    "                for win_idx, spec in enumerate(spectrograms):\n",
    "                    spec_tensor = torch.from_numpy(spec).float()\n",
    "                    spec_tensor = spec_tensor.permute(2, 0, 1).unsqueeze(0)  # (1, T, C, F)\n",
    "                    \n",
    "                    subject_spectrograms.append(spec_tensor)\n",
    "                    subject_metadata.append({\n",
    "                        'sentence_idx': sent_idx,\n",
    "                        'window_idx': win_idx,\n",
    "                        'task': task_name\n",
    "                    })\n",
    "            \n",
    "            # Save subject file\n",
    "            if len(subject_spectrograms) > 0:\n",
    "                spectrograms_tensor = torch.stack(subject_spectrograms, dim=0)\n",
    "                \n",
    "                pt_path = task_dir / split / f\"{subject_id}.pt\"\n",
    "                torch.save({\n",
    "                    'spectrograms': spectrograms_tensor,\n",
    "                    'metadata': subject_metadata,\n",
    "                    'subject': subject_id,\n",
    "                    'split': split\n",
    "                }, pt_path)\n",
    "                \n",
    "                file_size_mb = pt_path.stat().st_size / (1024 * 1024)\n",
    "                task_stats[split][subject_id] = len(subject_spectrograms)\n",
    "                print(f\"  {split}/{subject_id}.pt: {len(subject_spectrograms)} samples, {file_size_mb:.1f} MB\")\n",
    "        \n",
    "        stats[task_name] = task_stats\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Process EEG-VJEPA data\n",
    "vjepa_stats = process_vjepa_data_by_subject(all_data, OUTPUT_DIR_VJEPA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb59c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 5. EEG-to-Text Preprocessing Functions\n",
    "\n",
    "# %%\n",
    "def preprocess_eeg_for_e2t(\n",
    "    raw_eeg: np.ndarray,\n",
    "    max_length: int = MAX_EEG_LENGTH,\n",
    "    target_channels: int = TARGET_CHANNELS\n",
    ") -> Tuple[torch.Tensor, int]:\n",
    "    \"\"\"Preprocess raw EEG for EEG-to-Text decoding.\"\"\"\n",
    "    n_channels, n_samples = raw_eeg.shape\n",
    "    \n",
    "    if n_samples < max_length:\n",
    "        padded = np.zeros((n_channels, max_length), dtype=np.float32)\n",
    "        padded[:, :n_samples] = raw_eeg\n",
    "        eeg_data = padded\n",
    "        actual_length = n_samples\n",
    "    else:\n",
    "        eeg_data = raw_eeg[:, :max_length].astype(np.float32)\n",
    "        actual_length = max_length\n",
    "    \n",
    "    mean = eeg_data.mean(axis=1, keepdims=True)\n",
    "    std = eeg_data.std(axis=1, keepdims=True) + 1e-8\n",
    "    eeg_data = (eeg_data - mean) / std\n",
    "    \n",
    "    return torch.from_numpy(eeg_data), actual_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f93501e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EEG-TO-TEXT PREPROCESSING (SUBJECT-BASED)\n",
      "============================================================\n",
      "\n",
      "========================================\n",
      "Processing task1-SR...\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:   8%|▊         | 1/12 [00:06<01:11,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZAB.pt: 392 samples, 1256.2 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  17%|█▋        | 2/12 [00:23<02:04, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZDM.pt: 384 samples, 1230.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  25%|██▌       | 3/12 [00:33<01:44, 11.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZDN.pt: 294 samples, 942.1 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  33%|███▎      | 4/12 [00:49<01:46, 13.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZGW.pt: 376 samples, 1204.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  42%|████▏     | 5/12 [01:04<01:38, 14.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJM.pt: 400 samples, 1281.8 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  50%|█████     | 6/12 [01:21<01:30, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJN.pt: 384 samples, 1230.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  58%|█████▊    | 7/12 [01:31<01:06, 13.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJS.pt: 338 samples, 1083.1 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  67%|██████▋   | 8/12 [01:47<00:55, 13.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKB.pt: 399 samples, 1278.6 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  75%|███████▌  | 9/12 [01:58<00:39, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKH.pt: 392 samples, 1256.2 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  83%|████████▎ | 10/12 [02:12<00:26, 13.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZKW.pt: 399 samples, 1278.6 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects:  92%|█████████▏| 11/12 [02:27<00:13, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  val/ZMG.pt: 386 samples, 1236.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR subjects: 100%|██████████| 12/12 [02:39<00:00, 13.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test/ZPH.pt: 393 samples, 1259.4 MB\n",
      "\n",
      "========================================\n",
      "Processing task2-NR...\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:   8%|▊         | 1/12 [00:10<01:58, 10.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZAB.pt: 295 samples, 945.3 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  17%|█▋        | 2/12 [00:21<01:46, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZDM.pt: 292 samples, 935.7 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  25%|██▌       | 3/12 [01:05<03:55, 26.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZDN.pt: 298 samples, 954.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  33%|███▎      | 4/12 [01:08<02:15, 16.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZGW.pt: 281 samples, 900.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  42%|████▏     | 5/12 [01:14<01:30, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJM.pt: 258 samples, 826.8 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  50%|█████     | 6/12 [01:26<01:15, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJN.pt: 294 samples, 942.1 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  58%|█████▊    | 7/12 [01:34<00:55, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train/ZJS.pt: 217 samples, 695.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR subjects:  58%|█████▊    | 7/12 [01:38<01:10, 14.01s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:664] . unexpected pos 50752 vs 50646",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:967\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 967\u001b[0m     _save(\n\u001b[0;32m    968\u001b[0m         obj,\n\u001b[0;32m    969\u001b[0m         opened_zipfile,\n\u001b[0;32m    970\u001b[0m         pickle_module,\n\u001b[0;32m    971\u001b[0m         pickle_protocol,\n\u001b[0;32m    972\u001b[0m         _disable_byteorder_record,\n\u001b[0;32m    973\u001b[0m     )\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:1268\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m-> 1268\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(name, storage, num_bytes)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:863] . PytorchStreamWriter failed writing file data/0: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 100\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stats\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Process EEG-to-Text data\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m e2t_stats \u001b[38;5;241m=\u001b[39m process_e2t_data_by_subject(all_data, OUTPUT_DIR_E2T)\n",
      "Cell \u001b[1;32mIn[14], line 82\u001b[0m, in \u001b[0;36mprocess_e2t_data_by_subject\u001b[1;34m(all_data, output_dir)\u001b[0m\n\u001b[0;32m     79\u001b[0m eeg_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(subject_eeg, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     81\u001b[0m pt_path \u001b[38;5;241m=\u001b[39m task_dir \u001b[38;5;241m/\u001b[39m split \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 82\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m'\u001b[39m: eeg_tensor,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtexts\u001b[39m\u001b[38;5;124m'\u001b[39m: subject_texts,\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual_lengths\u001b[39m\u001b[38;5;124m'\u001b[39m: subject_lengths,\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m: subject_metadata,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m: subject_id,\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m'\u001b[39m: split\n\u001b[0;32m     89\u001b[0m }, pt_path)\n\u001b[0;32m     91\u001b[0m file_size_mb \u001b[38;5;241m=\u001b[39m pt_path\u001b[38;5;241m.\u001b[39mstat()\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m     92\u001b[0m task_stats[split][subject_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(subject_eeg)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:966\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    963\u001b[0m     f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(f)\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 966\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    967\u001b[0m         _save(\n\u001b[0;32m    968\u001b[0m             obj,\n\u001b[0;32m    969\u001b[0m             opened_zipfile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    972\u001b[0m             _disable_byteorder_record,\n\u001b[0;32m    973\u001b[0m         )\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:798\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_like\u001b[38;5;241m.\u001b[39mwrite_end_of_file()\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:664] . unexpected pos 50752 vs 50646"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 6. Process EEG-to-Text Data (SUBJECT-BASED)\n",
    "\n",
    "# %%\n",
    "def process_e2t_data_by_subject(all_data: Dict, output_dir: Path):\n",
    "    \"\"\"\n",
    "    Process all pickle data for EEG-to-Text decoding.\n",
    "    \n",
    "    Creates SUBJECT-BASED folder structure:\n",
    "    output_dir/\n",
    "    ├── task1-SR/\n",
    "    │   ├── train/\n",
    "    │   │   ├── ZAB.pt      # All EEG+text for subject ZAB\n",
    "    │   │   ├── ZDM.pt\n",
    "    │   │   └── ...\n",
    "    │   ├── val/\n",
    "    │   │   └── ZMG.pt\n",
    "    │   └── test/\n",
    "    │       └── ZPH.pt\n",
    "    └── ...\n",
    "    \n",
    "    Each .pt file contains:\n",
    "        - eeg: tensor of shape (N, channels, time) for this subject\n",
    "        - texts: list of sentence strings\n",
    "        - actual_lengths: list of original EEG lengths\n",
    "        - metadata: list of dicts with sentence_idx, task\n",
    "        - subject: subject ID\n",
    "        - split: train/val/test\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EEG-TO-TEXT PREPROCESSING (SUBJECT-BASED)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    stats = {}\n",
    "    \n",
    "    for task_name, task_data in all_data.items():\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"Processing {task_name}...\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        task_dir = output_dir / task_name\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            (task_dir / split).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        task_stats = {'train': {}, 'val': {}, 'test': {}}\n",
    "        \n",
    "        for subject_id, sentences in tqdm(task_data.items(), desc=f\"{task_name} subjects\"):\n",
    "            split = get_subject_split(subject_id)\n",
    "            \n",
    "            subject_eeg = []\n",
    "            subject_texts = []\n",
    "            subject_lengths = []\n",
    "            subject_metadata = []\n",
    "            \n",
    "            for sent_idx, sent in enumerate(sentences):\n",
    "                if sent is None:\n",
    "                    continue\n",
    "                \n",
    "                raw_eeg = sent['sentence_level_EEG']['rawData']\n",
    "                content = sent.get('content', '')\n",
    "                \n",
    "                if not content or len(content.strip()) == 0:\n",
    "                    continue\n",
    "                \n",
    "                eeg_tensor, actual_length = preprocess_eeg_for_e2t(raw_eeg)\n",
    "                \n",
    "                subject_eeg.append(eeg_tensor)\n",
    "                subject_texts.append(content)\n",
    "                subject_lengths.append(actual_length)\n",
    "                subject_metadata.append({\n",
    "                    'sentence_idx': sent_idx,\n",
    "                    'task': task_name\n",
    "                })\n",
    "            \n",
    "            # Save subject file\n",
    "            if len(subject_eeg) > 0:\n",
    "                eeg_tensor = torch.stack(subject_eeg, dim=0)\n",
    "                \n",
    "                pt_path = task_dir / split / f\"{subject_id}.pt\"\n",
    "                torch.save({\n",
    "                    'eeg': eeg_tensor,\n",
    "                    'texts': subject_texts,\n",
    "                    'actual_lengths': subject_lengths,\n",
    "                    'metadata': subject_metadata,\n",
    "                    'subject': subject_id,\n",
    "                    'split': split\n",
    "                }, pt_path)\n",
    "                \n",
    "                file_size_mb = pt_path.stat().st_size / (1024 * 1024)\n",
    "                task_stats[split][subject_id] = len(subject_eeg)\n",
    "                print(f\"  {split}/{subject_id}.pt: {len(subject_eeg)} samples, {file_size_mb:.1f} MB\")\n",
    "        \n",
    "        stats[task_name] = task_stats\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Process EEG-to-Text data\n",
    "e2t_stats = process_e2t_data_by_subject(all_data, OUTPUT_DIR_E2T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d4eb05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 7. Create PyTorch Dataset Classes (Subject-Based)\n",
    "\n",
    "# %%\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EEGVJEPADatasetSubjects(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for EEG-VJEPA pretraining (loads subject-based .pt files).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str, split: str = 'train', tasks: List[str] = None,\n",
    "                 subjects: List[str] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: Path to preprocessed_vjepa_subjects directory\n",
    "            split: 'train', 'val', or 'test'\n",
    "            tasks: List of tasks to include (default: all)\n",
    "            subjects: List of specific subjects to include (default: all in split)\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.split = split\n",
    "        \n",
    "        if tasks is None:\n",
    "            tasks = ['task1-SR', 'task2-NR', 'task3-TSR']\n",
    "        \n",
    "        # Determine which subjects to load\n",
    "        if subjects is None:\n",
    "            if split == 'train':\n",
    "                subjects = TRAIN_SUBJECTS\n",
    "            elif split == 'val':\n",
    "                subjects = VAL_SUBJECTS\n",
    "            else:\n",
    "                subjects = TEST_SUBJECTS\n",
    "        \n",
    "        # Load all subject files\n",
    "        all_spectrograms = []\n",
    "        all_metadata = []\n",
    "        \n",
    "        for task in tasks:\n",
    "            for subject in subjects:\n",
    "                pt_path = self.data_dir / task / split / f\"{subject}.pt\"\n",
    "                if pt_path.exists():\n",
    "                    data = torch.load(pt_path, weights_only=False)\n",
    "                    all_spectrograms.append(data['spectrograms'])\n",
    "                    # Add subject to each metadata entry\n",
    "                    for m in data['metadata']:\n",
    "                        m['subject'] = subject\n",
    "                    all_metadata.extend(data['metadata'])\n",
    "        \n",
    "        if len(all_spectrograms) > 0:\n",
    "            self.spectrograms = torch.cat(all_spectrograms, dim=0)\n",
    "            self.metadata = all_metadata\n",
    "        else:\n",
    "            self.spectrograms = torch.tensor([])\n",
    "            self.metadata = []\n",
    "        \n",
    "        print(f\"[{split}] Loaded {len(self)} samples from {len(subjects)} subjects, {len(tasks)} tasks\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.spectrograms)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.spectrograms[idx]\n",
    "    \n",
    "    def get_metadata(self, idx):\n",
    "        return self.metadata[idx]\n",
    "\n",
    "\n",
    "class EEGToTextDatasetSubjects(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for EEG-to-Text decoding (loads subject-based .pt files).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str, split: str = 'train', tasks: List[str] = None,\n",
    "                 subjects: List[str] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: Path to preprocessed_e2t_subjects directory\n",
    "            split: 'train', 'val', or 'test'\n",
    "            tasks: List of tasks to include (default: all)\n",
    "            subjects: List of specific subjects to include (default: all in split)\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.split = split\n",
    "        \n",
    "        if tasks is None:\n",
    "            tasks = ['task1-SR', 'task2-NR', 'task3-TSR']\n",
    "        \n",
    "        if subjects is None:\n",
    "            if split == 'train':\n",
    "                subjects = TRAIN_SUBJECTS\n",
    "            elif split == 'val':\n",
    "                subjects = VAL_SUBJECTS\n",
    "            else:\n",
    "                subjects = TEST_SUBJECTS\n",
    "        \n",
    "        all_eeg = []\n",
    "        all_texts = []\n",
    "        all_lengths = []\n",
    "        all_metadata = []\n",
    "        \n",
    "        for task in tasks:\n",
    "            for subject in subjects:\n",
    "                pt_path = self.data_dir / task / split / f\"{subject}.pt\"\n",
    "                if pt_path.exists():\n",
    "                    data = torch.load(pt_path, weights_only=False)\n",
    "                    all_eeg.append(data['eeg'])\n",
    "                    all_texts.extend(data['texts'])\n",
    "                    all_lengths.extend(data['actual_lengths'])\n",
    "                    for m in data['metadata']:\n",
    "                        m['subject'] = subject\n",
    "                    all_metadata.extend(data['metadata'])\n",
    "        \n",
    "        if len(all_eeg) > 0:\n",
    "            self.eeg = torch.cat(all_eeg, dim=0)\n",
    "            self.texts = all_texts\n",
    "            self.actual_lengths = all_lengths\n",
    "            self.metadata = all_metadata\n",
    "        else:\n",
    "            self.eeg = torch.tensor([])\n",
    "            self.texts = []\n",
    "            self.actual_lengths = []\n",
    "            self.metadata = []\n",
    "        \n",
    "        print(f\"[{split}] Loaded {len(self)} samples from {len(subjects)} subjects, {len(tasks)} tasks\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.eeg)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'eeg': self.eeg[idx],\n",
    "            'text': self.texts[idx],\n",
    "            'actual_length': self.actual_lengths[idx],\n",
    "            'subject': self.metadata[idx]['subject']\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "761b6516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VALIDATION\n",
      "============================================================\n",
      "\n",
      "EEG-VJEPA Preprocessed Data (Subject-Based):\n",
      "\n",
      "  task1-SR:\n",
      "    train/ZAB.pt: 3539 samples, 1356.6 MB\n",
      "    train/ZDM.pt: 3109 samples, 1191.8 MB\n",
      "    train/ZDN.pt: 2097 samples, 803.9 MB\n",
      "    train/ZGW.pt: 4851 samples, 1859.6 MB\n",
      "    train/ZJM.pt: 4647 samples, 1781.4 MB\n",
      "    train/ZJN.pt: 6332 samples, 2427.3 MB\n",
      "    train/ZJS.pt: 2694 samples, 1032.7 MB\n",
      "    train/ZKB.pt: 4001 samples, 1533.7 MB\n",
      "    train/ZKH.pt: 3957 samples, 1516.9 MB\n",
      "    train/ZKW.pt: 5216 samples, 1999.5 MB\n",
      "    train total: 40443 samples\n",
      "    val/ZMG.pt: 3116 samples, 1194.5 MB\n",
      "    val total: 3116 samples\n",
      "    test/ZPH.pt: 3468 samples, 1329.4 MB\n",
      "    test total: 3468 samples\n",
      "\n",
      "  task2-NR:\n",
      "    train/ZAB.pt: 2814 samples, 1078.7 MB\n",
      "    train/ZDM.pt: 2782 samples, 1066.5 MB\n",
      "    train/ZDN.pt: 2229 samples, 854.5 MB\n",
      "    train/ZGW.pt: 4296 samples, 1646.8 MB\n",
      "    train/ZJM.pt: 4271 samples, 1637.2 MB\n",
      "    train/ZJN.pt: 6338 samples, 2429.6 MB\n",
      "    train/ZJS.pt: 1663 samples, 637.5 MB\n",
      "    train/ZKB.pt: 4743 samples, 1818.2 MB\n",
      "    train/ZKH.pt: 3549 samples, 1360.5 MB\n",
      "    train/ZKW.pt: 6626 samples, 2540.0 MB\n",
      "    train total: 39311 samples\n",
      "    val/ZMG.pt: 2840 samples, 1088.7 MB\n",
      "    val total: 2840 samples\n",
      "    test/ZPH.pt: 3510 samples, 1345.5 MB\n",
      "    test total: 3510 samples\n",
      "\n",
      "  task3-TSR:\n",
      "    train/ZAB.pt: 2328 samples, 892.4 MB\n",
      "    train/ZDM.pt: 2367 samples, 907.4 MB\n",
      "    train/ZDN.pt: 2124 samples, 814.2 MB\n",
      "    train/ZGW.pt: 2689 samples, 1030.8 MB\n",
      "    train/ZJM.pt: 4797 samples, 1838.9 MB\n",
      "    train/ZJN.pt: 5306 samples, 2034.0 MB\n",
      "    train/ZJS.pt: 1859 samples, 712.6 MB\n",
      "    train/ZKB.pt: 1522 samples, 583.4 MB\n",
      "    train/ZKH.pt: 3945 samples, 1512.3 MB\n",
      "    train/ZKW.pt: 4679 samples, 1793.6 MB\n",
      "    train total: 31616 samples\n",
      "    val/ZMG.pt: 2739 samples, 1050.0 MB\n",
      "    val total: 2739 samples\n",
      "    test/ZPH.pt: 1493 samples, 572.3 MB\n",
      "    test total: 1493 samples\n",
      "\n",
      " Total VJEPA size: 49272.9 MB (48.12 GB)\n",
      "\n",
      "EEG-to-Text Preprocessed Data (Subject-Based):\n",
      "\n",
      "  task1-SR:\n",
      "    train/ZAB.pt: 392 samples, 1256.2 MB\n",
      "    train/ZDM.pt: 384 samples, 1230.5 MB\n",
      "    train/ZDN.pt: 294 samples, 942.1 MB\n",
      "    train/ZGW.pt: 376 samples, 1204.9 MB\n",
      "    train/ZJM.pt: 400 samples, 1281.8 MB\n",
      "    train/ZJN.pt: 384 samples, 1230.5 MB\n",
      "    train/ZJS.pt: 338 samples, 1083.1 MB\n",
      "    train/ZKB.pt: 399 samples, 1278.6 MB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  EEGToTextDatasetSubjects: ✗ (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Run validation\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m validate_preprocessing()\n",
      "Cell \u001b[1;32mIn[16], line 46\u001b[0m, in \u001b[0;36mvalidate_preprocessing\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m split_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pt_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(files):\n\u001b[1;32m---> 46\u001b[0m     data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(pt_path, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     48\u001b[0m     size_mb \u001b[38;5;241m=\u001b[39m pt_path\u001b[38;5;241m.\u001b[39mstat()\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:1530\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1528\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1529\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1531\u001b[0m             opened_zipfile,\n\u001b[0;32m   1532\u001b[0m             map_location,\n\u001b[0;32m   1533\u001b[0m             pickle_module,\n\u001b[0;32m   1534\u001b[0m             overall_storage\u001b[38;5;241m=\u001b[39moverall_storage,\n\u001b[0;32m   1535\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1536\u001b[0m         )\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[0;32m   1538\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:2122\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   2120\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[0;32m   2121\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 2122\u001b[0m result \u001b[38;5;241m=\u001b[39m unpickler\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m   2123\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2125\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:2086\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2085\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 2086\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m load_tensor(\n\u001b[0;32m   2087\u001b[0m         dtype, nbytes, key, _maybe_decode_ascii(location)\n\u001b[0;32m   2088\u001b[0m     )\n\u001b[0;32m   2090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:2039\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   2032\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m storage_offset \u001b[38;5;241m!=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_record_offset(name):\n\u001b[0;32m   2033\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2034\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a debug assert that was run as the `TORCH_SERIALIZATION_DEBUG` environment \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2035\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable was set: Incorrect offset for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstorage_offset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2036\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_file\u001b[38;5;241m.\u001b[39mget_record_offset(name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2037\u001b[0m             )\n\u001b[0;32m   2038\u001b[0m     storage \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 2039\u001b[0m         zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\n\u001b[0;32m   2040\u001b[0m         \u001b[38;5;241m.\u001b[39m_typed_storage()\n\u001b[0;32m   2041\u001b[0m         \u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[0;32m   2042\u001b[0m     )\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[0;32m   2044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 8. Validation & Statistics\n",
    "\n",
    "# %%\n",
    "def validate_preprocessing():\n",
    "    \"\"\"Validate the preprocessed data.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check EEG-VJEPA data\n",
    "    print(\"\\nEEG-VJEPA Preprocessed Data (Subject-Based):\")\n",
    "    total_vjepa_size = 0\n",
    "    for task in ['task1-SR', 'task2-NR', 'task3-TSR']:\n",
    "        print(f\"\\n  {task}:\")\n",
    "        task_dir = OUTPUT_DIR_VJEPA / task\n",
    "        if task_dir.exists():\n",
    "            for split in ['train', 'val', 'test']:\n",
    "                split_dir = task_dir / split\n",
    "                if split_dir.exists():\n",
    "                    files = list(split_dir.glob('*.pt'))\n",
    "                    split_total = 0\n",
    "                    for pt_path in sorted(files):\n",
    "                        data = torch.load(pt_path, weights_only=False)\n",
    "                        n_samples = data['spectrograms'].shape[0]\n",
    "                        size_mb = pt_path.stat().st_size / (1024 * 1024)\n",
    "                        total_vjepa_size += size_mb\n",
    "                        split_total += n_samples\n",
    "                        print(f\"    {split}/{pt_path.name}: {n_samples} samples, {size_mb:.1f} MB\")\n",
    "                    print(f\"    {split} total: {split_total} samples\")\n",
    "    print(f\"\\n Total VJEPA size: {total_vjepa_size:.1f} MB ({total_vjepa_size/1024:.2f} GB)\")\n",
    "    \n",
    "    # Check EEG-to-Text data\n",
    "    print(\"\\nEEG-to-Text Preprocessed Data (Subject-Based):\")\n",
    "    total_e2t_size = 0\n",
    "    for task in ['task1-SR', 'task2-NR', 'task3-TSR']:\n",
    "        print(f\"\\n  {task}:\")\n",
    "        task_dir = OUTPUT_DIR_E2T / task\n",
    "        if task_dir.exists():\n",
    "            for split in ['train', 'val', 'test']:\n",
    "                split_dir = task_dir / split\n",
    "                if split_dir.exists():\n",
    "                    files = list(split_dir.glob('*.pt'))\n",
    "                    split_total = 0\n",
    "                    for pt_path in sorted(files):\n",
    "                        data = torch.load(pt_path, weights_only=False)\n",
    "                        n_samples = data['eeg'].shape[0]\n",
    "                        size_mb = pt_path.stat().st_size / (1024 * 1024)\n",
    "                        total_e2t_size += size_mb\n",
    "                        split_total += n_samples\n",
    "                        print(f\"    {split}/{pt_path.name}: {n_samples} samples, {size_mb:.1f} MB\")\n",
    "                    print(f\"    {split} total: {split_total} samples\")\n",
    "    print(f\"\\n Total E2T size: {total_e2t_size:.1f} MB ({total_e2t_size/1024:.2f} GB)\")\n",
    "    \n",
    "    # Test dataset classes\n",
    "    print(\"\\nTesting Dataset Classes:\")\n",
    "    try:\n",
    "        vjepa_ds = EEGVJEPADatasetSubjects(OUTPUT_DIR_VJEPA, split='train')\n",
    "        if len(vjepa_ds) > 0:\n",
    "            sample = vjepa_ds[0]\n",
    "            print(f\"  EEGVJEPADatasetSubjects: ✓ ({len(vjepa_ds)} samples, shape={sample.shape})\")\n",
    "    except Exception as e:\n",
    "        print(f\"  EEGVJEPADatasetSubjects: ✗ ({e})\")\n",
    "    \n",
    "    try:\n",
    "        e2t_ds = EEGToTextDatasetSubjects(OUTPUT_DIR_E2T, split='train')\n",
    "        if len(e2t_ds) > 0:\n",
    "            sample = e2t_ds[0]\n",
    "            print(f\"  EEGToTextDatasetSubjects: ✓ ({len(e2t_ds)} samples)\")\n",
    "            print(f\"    EEG shape: {sample['eeg'].shape}\")\n",
    "            text_preview = sample['text'][:50] + \"...\" if len(sample['text']) > 50 else sample['text']\n",
    "            print(f\"    Text: \\\"{text_preview}\\\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"  EEGToTextDatasetSubjects: ✗ ({e})\")\n",
    "\n",
    "# Run validation\n",
    "validate_preprocessing()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 9. Summary\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Output Directories:\n",
    "  EEG-VJEPA: {OUTPUT_DIR_VJEPA}\n",
    "  EEG-to-Text: {OUTPUT_DIR_E2T}\n",
    "\n",
    "File Structure (SUBJECT-BASED):\n",
    "  preprocessed_vjepa_subjects/\n",
    "  ├── task1-SR/\n",
    "  │   ├── train/\n",
    "  │   │   ├── ZAB.pt    # All spectrograms for ZAB\n",
    "  │   │   ├── ZDM.pt    # All spectrograms for ZDM\n",
    "  │   │   ├── ZGW.pt\n",
    "  │   │   ├── ZJM.pt\n",
    "  │   │   ├── ZJN.pt\n",
    "  │   │   ├── ZJS.pt\n",
    "  │   │   ├── ZKB.pt\n",
    "  │   │   ├── ZKH.pt\n",
    "  │   │   └── ZKW.pt    # (9 train subjects)\n",
    "  │   ├── val/\n",
    "  │   │   └── ZMG.pt    # (1 val subject)\n",
    "  │   └── test/\n",
    "  │       └── ZPH.pt    # (1 test subject)\n",
    "  ├── task2-NR/\n",
    "  │   └── ...\n",
    "  └── task3-TSR/\n",
    "      └── ...\n",
    "\n",
    "Subject Splits:\n",
    "  Train ({len(TRAIN_SUBJECTS)} subjects): {TRAIN_SUBJECTS}\n",
    "  Val ({len(VAL_SUBJECTS)} subjects): {VAL_SUBJECTS}\n",
    "  Test ({len(TEST_SUBJECTS)} subjects): {TEST_SUBJECTS}\n",
    "\n",
    "Total files per format:\n",
    "  ~{len(ALL_SUBJECTS) * 3} files for VJEPA (11 subjects × 3 tasks)\n",
    "  ~{len(ALL_SUBJECTS) * 3} files for E2T (11 subjects × 3 tasks)\n",
    "\n",
    "Usage:\n",
    "```python\n",
    "# Load EEG-VJEPA dataset (all train subjects)\n",
    "from preprocess_spector_subjects import EEGVJEPADatasetSubjects\n",
    "train_ds = EEGVJEPADatasetSubjects('{OUTPUT_DIR_VJEPA}', split='train')\n",
    "\n",
    "# Load specific subjects only\n",
    "custom_ds = EEGVJEPADatasetSubjects(\n",
    "    '{OUTPUT_DIR_VJEPA}', \n",
    "    split='train', \n",
    "    subjects=['ZAB', 'ZDM']  # Only load these subjects\n",
    ")\n",
    "\n",
    "# Load EEG-to-Text dataset  \n",
    "from preprocess_spector_subjects import EEGToTextDatasetSubjects\n",
    "train_ds = EEGToTextDatasetSubjects('{OUTPUT_DIR_E2T}', split='train')\n",
    "```\n",
    "\n",
    "✨ Benefits of subject-based format:\n",
    "  - ~33 files per task instead of thousands\n",
    "  - Easy to add/remove subjects\n",
    "  - Good file size (~1-5 GB each)\n",
    "  - Natural split organization\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
