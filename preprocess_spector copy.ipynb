{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fd5781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\n",
      "Output VJEPA: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\preprocessed_vjepa\n",
      "Output E2T: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\preprocessed_e2t\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Configuration\n",
    "TRAIN_SUBJECTS = ['ZAB', 'ZDM', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW']\n",
    "VAL_SUBJECTS = ['ZMG']\n",
    "TEST_SUBJECTS = ['ZPH']\n",
    "\n",
    "# Paths - Update these to match your setup\n",
    "BASE_DIR = Path(r\"c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\")\n",
    "PICKLE_DIR = BASE_DIR / \"src\" / \"datasets\" / \"ZuCo\"\n",
    "\n",
    "# Pickle file paths\n",
    "PICKLE_FILES = {\n",
    "    'task1-SR': PICKLE_DIR / \"task1-SR\" / \"pickle\" / \"task1-SR-dataset-spectro.pickle\",\n",
    "    'task2-NR': PICKLE_DIR / \"task2-NR\" / \"pickle\" / \"task2-NR-dataset-spectro.pickle\",\n",
    "    'task3-TSR': PICKLE_DIR / \"task3-TSR\" / \"pickle\" / \"task3-TSR-dataset-spectro.pickle\",\n",
    "}\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR_VJEPA = BASE_DIR / \"src\" / \"datasets\" / \"preprocessed_vjepa\"\n",
    "OUTPUT_DIR_E2T = BASE_DIR / \"src\" / \"datasets\" / \"preprocessed_e2t\"\n",
    "\n",
    "# EEG-VJEPA preprocessing parameters\n",
    "TIME_WINDOW = 512  # ~1 sec at 500 Hz\n",
    "N_FFT = 64\n",
    "HOP_LENGTH = 16\n",
    "OVERLAP = 0.5  # 50% overlap between windows\n",
    "\n",
    "# EEG-to-Text preprocessing parameters\n",
    "MAX_EEG_LENGTH = 8000  # Maximum EEG sequence length (pad/truncate)\n",
    "TARGET_CHANNELS = 105  # Expected number of EEG channels\n",
    "\n",
    "print(f\"Base Directory: {BASE_DIR}\")\n",
    "print(f\"Output VJEPA: {OUTPUT_DIR_VJEPA}\")\n",
    "print(f\"Output E2T: {OUTPUT_DIR_E2T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0ddea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\ZuCo\\task1-SR\\pickle\\task1-SR-dataset-spectro.pickle\n",
      "\n",
      "============================================================\n",
      "Exploring: task1-SR\n",
      "============================================================\n",
      "Subjects (12): ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "  ZAB: 392 valid sentences\n",
      "  ZDM: 384 valid sentences\n",
      "  ZDN: 294 valid sentences\n",
      "  ZGW: 376 valid sentences\n",
      "  ZJM: 400 valid sentences\n",
      "  ZJN: 384 valid sentences\n",
      "  ZJS: 338 valid sentences\n",
      "  ZKB: 399 valid sentences\n",
      "  ZKH: 392 valid sentences\n",
      "  ZKW: 399 valid sentences\n",
      "  ZMG: 386 valid sentences\n",
      "  ZPH: 393 valid sentences\n",
      "\n",
      "Data Statistics:\n",
      "  Channels: {105}\n",
      "  Time range: [39, 14819]\n",
      "  Mean length: 2783.2\n",
      "  Total valid samples: 4537\n",
      "Loading: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\ZuCo\\task2-NR\\pickle\\task2-NR-dataset-spectro.pickle\n",
      "\n",
      "============================================================\n",
      "Exploring: task2-NR\n",
      "============================================================\n",
      "Subjects (12): ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "  ZAB: 295 valid sentences\n",
      "  ZDM: 292 valid sentences\n",
      "  ZDN: 298 valid sentences\n",
      "  ZGW: 281 valid sentences\n",
      "  ZJM: 258 valid sentences\n",
      "  ZJN: 294 valid sentences\n",
      "  ZJS: 217 valid sentences\n",
      "  ZKB: 297 valid sentences\n",
      "  ZKH: 294 valid sentences\n",
      "  ZKW: 296 valid sentences\n",
      "  ZMG: 287 valid sentences\n",
      "  ZPH: 247 valid sentences\n",
      "\n",
      "Data Statistics:\n",
      "  Channels: {105}\n",
      "  Time range: [15, 23630]\n",
      "  Mean length: 3611.7\n",
      "  Total valid samples: 3356\n",
      "Loading: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\ZuCo\\task3-TSR\\pickle\\task3-TSR-dataset-spectro.pickle\n",
      "\n",
      "============================================================\n",
      "Exploring: task3-TSR\n",
      "============================================================\n",
      "Subjects (12): ['ZAB', 'ZDM', 'ZDN', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW', 'ZMG', 'ZPH']\n",
      "  ZAB: 388 valid sentences\n",
      "  ZDM: 397 valid sentences\n",
      "  ZDN: 406 valid sentences\n",
      "  ZGW: 352 valid sentences\n",
      "  ZJM: 407 valid sentences\n",
      "  ZJN: 397 valid sentences\n",
      "  ZJS: 362 valid sentences\n",
      "  ZKB: 359 valid sentences\n",
      "  ZKH: 381 valid sentences\n",
      "  ZKW: 407 valid sentences\n",
      "  ZMG: 404 valid sentences\n",
      "  ZPH: 317 valid sentences\n",
      "\n",
      "Data Statistics:\n",
      "  Channels: {105}\n",
      "  Time range: [28, 22727]\n",
      "  Mean length: 2137.6\n",
      "  Total valid samples: 4577\n"
     ]
    }
   ],
   "source": [
    "def load_pickle_data(pickle_path: Path) -> Dict:\n",
    "    \"\"\"Load a pickle file and return the data.\"\"\"\n",
    "    print(f\"Loading: {pickle_path}\")\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def explore_pickle_data(data: Dict, task_name: str):\n",
    "    \"\"\"Explore the structure of a pickle file.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Exploring: {task_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    subjects = list(data.keys())\n",
    "    print(f\"Subjects ({len(subjects)}): {subjects}\")\n",
    "    \n",
    "    total_samples = 0\n",
    "    sample_shapes = []\n",
    "    \n",
    "    for subj in subjects:\n",
    "        valid_count = 0\n",
    "        for sent in data[subj]:\n",
    "            if sent is not None:\n",
    "                valid_count += 1\n",
    "                total_samples += 1\n",
    "                raw = sent['sentence_level_EEG']['rawData']\n",
    "                sample_shapes.append(raw.shape)\n",
    "        print(f\"  {subj}: {valid_count} valid sentences\")\n",
    "    \n",
    "    if sample_shapes:\n",
    "        channels = set(s[0] for s in sample_shapes)\n",
    "        time_lengths = [s[1] for s in sample_shapes]\n",
    "        print(f\"\\nData Statistics:\")\n",
    "        print(f\"  Channels: {channels}\")\n",
    "        print(f\"  Time range: [{min(time_lengths)}, {max(time_lengths)}]\")\n",
    "        print(f\"  Mean length: {np.mean(time_lengths):.1f}\")\n",
    "        print(f\"  Total valid samples: {total_samples}\")\n",
    "    \n",
    "    return total_samples\n",
    "\n",
    "\n",
    "# Load and explore all pickle files\n",
    "all_data = {}\n",
    "for task_name, pickle_path in PICKLE_FILES.items():\n",
    "    if pickle_path.exists():\n",
    "        all_data[task_name] = load_pickle_data(pickle_path)\n",
    "        explore_pickle_data(all_data[task_name], task_name)\n",
    "    else:\n",
    "        print(f\"⚠ Not found: {pickle_path}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. EEG-VJEPA Preprocessing Functions\n",
    "\n",
    "# %%\n",
    "def compute_spectrogram(eeg_data: np.ndarray, n_fft: int = 64, hop_length: int = 16) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute STFT spectrogram for each EEG channel.\n",
    "    \n",
    "    Args:\n",
    "        eeg_data: Raw EEG data of shape (n_channels, n_samples)\n",
    "        n_fft: FFT window size\n",
    "        hop_length: Hop length between windows\n",
    "        \n",
    "    Returns:\n",
    "        Spectrogram of shape (n_channels, n_freq_bins, n_time_bins)\n",
    "    \"\"\"\n",
    "    n_channels, n_samples = eeg_data.shape\n",
    "    \n",
    "    # Compute number of output dimensions\n",
    "    n_freq_bins = n_fft // 2 + 1\n",
    "    n_time_bins = (n_samples - n_fft) // hop_length + 1\n",
    "    \n",
    "    if n_time_bins <= 0:\n",
    "        # Pad if too short\n",
    "        pad_len = n_fft + hop_length - n_samples\n",
    "        eeg_data = np.pad(eeg_data, ((0, 0), (0, pad_len)), mode='constant')\n",
    "        n_samples = eeg_data.shape[1]\n",
    "        n_time_bins = (n_samples - n_fft) // hop_length + 1\n",
    "    \n",
    "    # Hanning window\n",
    "    window = np.hanning(n_fft)\n",
    "    \n",
    "    spectrogram = np.zeros((n_channels, n_freq_bins, n_time_bins), dtype=np.float32)\n",
    "    \n",
    "    for ch in range(n_channels):\n",
    "        for t in range(n_time_bins):\n",
    "            start_idx = t * hop_length\n",
    "            segment = eeg_data[ch, start_idx:start_idx + n_fft] * window\n",
    "            fft_result = np.fft.rfft(segment)\n",
    "            spectrogram[ch, :, t] = np.abs(fft_result)\n",
    "    \n",
    "    # Log-scale magnitude (add small epsilon for stability)\n",
    "    spectrogram = np.log1p(spectrogram)\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def extract_windows_and_spectrograms(\n",
    "    raw_eeg: np.ndarray,\n",
    "    time_window: int = 512,\n",
    "    overlap: float = 0.5,\n",
    "    n_fft: int = 64,\n",
    "    hop_length: int = 16\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract overlapping time windows and compute spectrograms.\n",
    "    \n",
    "    Args:\n",
    "        raw_eeg: Raw EEG data (channels, time)\n",
    "        time_window: Window size in samples\n",
    "        overlap: Overlap ratio (0.0 to 0.9)\n",
    "        n_fft: FFT size\n",
    "        hop_length: Hop length\n",
    "        \n",
    "    Returns:\n",
    "        List of spectrograms, each of shape (channels, freq_bins, time_bins)\n",
    "    \"\"\"\n",
    "    n_channels, n_samples = raw_eeg.shape\n",
    "    step_size = int(time_window * (1 - overlap))\n",
    "    \n",
    "    spectrograms = []\n",
    "    \n",
    "    # Skip if too short\n",
    "    if n_samples < time_window // 2:\n",
    "        return spectrograms\n",
    "    \n",
    "    # Extract overlapping windows\n",
    "    start = 0\n",
    "    while start + time_window <= n_samples:\n",
    "        window_data = raw_eeg[:, start:start + time_window]\n",
    "        spectrogram = compute_spectrogram(window_data, n_fft, hop_length)\n",
    "        \n",
    "        # Z-score normalize per channel\n",
    "        mean = spectrogram.mean(axis=(1, 2), keepdims=True)\n",
    "        std = spectrogram.std(axis=(1, 2), keepdims=True) + 1e-8\n",
    "        spectrogram = (spectrogram - mean) / std\n",
    "        \n",
    "        spectrograms.append(spectrogram)\n",
    "        start += step_size\n",
    "    \n",
    "    # Also get one window from the end if we have leftovers\n",
    "    if n_samples >= time_window and start < n_samples - time_window // 2:\n",
    "        window_data = raw_eeg[:, -time_window:]\n",
    "        spectrogram = compute_spectrogram(window_data, n_fft, hop_length)\n",
    "        mean = spectrogram.mean(axis=(1, 2), keepdims=True)\n",
    "        std = spectrogram.std(axis=(1, 2), keepdims=True) + 1e-8\n",
    "        spectrogram = (spectrogram - mean) / std\n",
    "        spectrograms.append(spectrogram)\n",
    "    \n",
    "    return spectrograms\n",
    "\n",
    "\n",
    "def get_subject_split(subject_id: str) -> str:\n",
    "    \"\"\"Determine which split a subject belongs to.\"\"\"\n",
    "    if subject_id in TRAIN_SUBJECTS:\n",
    "        return 'train'\n",
    "    elif subject_id in VAL_SUBJECTS:\n",
    "        return 'val'\n",
    "    elif subject_id in TEST_SUBJECTS:\n",
    "        return 'test'\n",
    "    else:\n",
    "        print(f\"⚠ Unknown subject {subject_id}, defaulting to train\")\n",
    "        return 'train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a412dc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EEG-VJEPA PREPROCESSING\n",
      "============================================================\n",
      "\n",
      "Processing task1-SR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR:  17%|█▋        | 2/12 [01:46<08:51, 53.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Unknown subject ZDN, defaulting to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR: 100%|██████████| 12/12 [13:30<00:00, 67.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  task1-SR complete:\n",
      "    train: 40443 samples\n",
      "    val: 3116 samples\n",
      "    test: 3468 samples\n",
      "\n",
      "Processing task2-NR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR:  17%|█▋        | 2/12 [01:29<07:28, 44.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Unknown subject ZDN, defaulting to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR: 100%|██████████| 12/12 [12:07<00:00, 60.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  task2-NR complete:\n",
      "    train: 39311 samples\n",
      "    val: 2840 samples\n",
      "    test: 3510 samples\n",
      "\n",
      "Processing task3-TSR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR:  17%|█▋        | 2/12 [01:14<06:09, 36.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Unknown subject ZDN, defaulting to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR: 100%|██████████| 12/12 [09:22<00:00, 46.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  task3-TSR complete:\n",
      "    train: 31616 samples\n",
      "    val: 2739 samples\n",
      "    test: 1493 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Process EEG-VJEPA Data\n",
    "\n",
    "# %%\n",
    "def process_vjepa_data(all_data: Dict, output_dir: Path):\n",
    "    \"\"\"\n",
    "    Process all pickle data for EEG-VJEPA pretraining.\n",
    "    \n",
    "    Creates folder structure:\n",
    "    output_dir/\n",
    "    ├── task1-SR/\n",
    "    │   ├── train/\n",
    "    │   │   ├── ZAB_s0_w0.pt\n",
    "    │   │   └── ...\n",
    "    │   ├── val/\n",
    "    │   └── test/\n",
    "    ├── task2-NR/\n",
    "    │   └── ...\n",
    "    └── task3-TSR/\n",
    "        └── ...\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EEG-VJEPA PREPROCESSING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    stats = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for task_name, task_data in all_data.items():\n",
    "        print(f\"\\nProcessing {task_name}...\")\n",
    "        \n",
    "        # Create output directories\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_dir = output_dir / task_name / split\n",
    "            split_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        sample_counts = {'train': 0, 'val': 0, 'test': 0}\n",
    "        \n",
    "        for subject_id, sentences in tqdm(task_data.items(), desc=task_name):\n",
    "            split = get_subject_split(subject_id)\n",
    "            split_dir = output_dir / task_name / split\n",
    "            \n",
    "            for sent_idx, sent in enumerate(sentences):\n",
    "                if sent is None:\n",
    "                    continue\n",
    "                \n",
    "                raw_eeg = sent['sentence_level_EEG']['rawData']\n",
    "                \n",
    "                # Extract spectrograms from overlapping windows\n",
    "                spectrograms = extract_windows_and_spectrograms(\n",
    "                    raw_eeg,\n",
    "                    time_window=TIME_WINDOW,\n",
    "                    overlap=OVERLAP,\n",
    "                    n_fft=N_FFT,\n",
    "                    hop_length=HOP_LENGTH\n",
    "                )\n",
    "                \n",
    "                # Save each spectrogram as separate .pt file\n",
    "                for win_idx, spec in enumerate(spectrograms):\n",
    "                    # Reshape for 3D ViT: (1, time_bins, channels, freq_bins)\n",
    "                    spec_tensor = torch.from_numpy(spec).float()\n",
    "                    spec_tensor = spec_tensor.permute(2, 0, 1).unsqueeze(0)  # (1, T, C, F)\n",
    "                    \n",
    "                    filename = f\"{task_name}_{subject_id}_s{sent_idx}_w{win_idx}.pt\"\n",
    "                    pt_path = split_dir / filename\n",
    "                    \n",
    "                    torch.save({\n",
    "                        'spectrogram': spec_tensor,\n",
    "                        'subject': subject_id,\n",
    "                        'sentence_idx': sent_idx,\n",
    "                        'window_idx': win_idx,\n",
    "                        'task': task_name\n",
    "                    }, pt_path)\n",
    "                    \n",
    "                    sample_counts[split] += 1\n",
    "        \n",
    "        # Print stats for this task\n",
    "        print(f\"  {task_name} complete:\")\n",
    "        for split, count in sample_counts.items():\n",
    "            print(f\"    {split}: {count} samples\")\n",
    "            stats[task_name][split] = count\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Process EEG-VJEPA data\n",
    "vjepa_stats = process_vjepa_data(all_data, OUTPUT_DIR_VJEPA)\n",
    "\n",
    "\n",
    "# ## 5. EEG-to-Text Preprocessing Functions\n",
    "\n",
    "# %%\n",
    "def preprocess_eeg_for_e2t(\n",
    "    raw_eeg: np.ndarray,\n",
    "    max_length: int = MAX_EEG_LENGTH,\n",
    "    target_channels: int = TARGET_CHANNELS\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Preprocess raw EEG for EEG-to-Text decoding.\n",
    "    \n",
    "    - Pad or truncate to max_length\n",
    "    - Z-score normalize\n",
    "    \n",
    "    Args:\n",
    "        raw_eeg: Raw EEG data (channels, time)\n",
    "        max_length: Target time dimension\n",
    "        target_channels: Expected number of channels\n",
    "        \n",
    "    Returns:\n",
    "        Preprocessed EEG tensor (channels, time)\n",
    "    \"\"\"\n",
    "    n_channels, n_samples = raw_eeg.shape\n",
    "    \n",
    "    # Validate channels\n",
    "    if n_channels != target_channels:\n",
    "        print(f\"⚠ Channel mismatch: expected {target_channels}, got {n_channels}\")\n",
    "    \n",
    "    # Pad or truncate time dimension\n",
    "    if n_samples < max_length:\n",
    "        # Pad with zeros\n",
    "        padded = np.zeros((n_channels, max_length), dtype=np.float32)\n",
    "        padded[:, :n_samples] = raw_eeg\n",
    "        eeg_data = padded\n",
    "        actual_length = n_samples\n",
    "    else:\n",
    "        # Truncate\n",
    "        eeg_data = raw_eeg[:, :max_length].astype(np.float32)\n",
    "        actual_length = max_length\n",
    "    \n",
    "    # Z-score normalize per channel\n",
    "    mean = eeg_data.mean(axis=1, keepdims=True)\n",
    "    std = eeg_data.std(axis=1, keepdims=True) + 1e-8\n",
    "    eeg_data = (eeg_data - mean) / std\n",
    "    \n",
    "    return torch.from_numpy(eeg_data), actual_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c145a9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EEG-TO-TEXT PREPROCESSING\n",
      "============================================================\n",
      "\n",
      "Processing task1-SR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR:  17%|█▋        | 2/12 [00:51<04:56, 29.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Unknown subject ZDN, defaulting to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task1-SR: 100%|██████████| 12/12 [02:41<00:00, 13.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  task1-SR complete:\n",
      "    train: 3758 samples\n",
      "    val: 386 samples\n",
      "    test: 393 samples\n",
      "  Text length: min=23, max=251, mean=106.2\n",
      "\n",
      "Processing task2-NR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR:  17%|█▋        | 2/12 [00:22<01:58, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Unknown subject ZDN, defaulting to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task2-NR: 100%|██████████| 12/12 [01:48<00:00,  9.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  task2-NR complete:\n",
      "    train: 2822 samples\n",
      "    val: 287 samples\n",
      "    test: 247 samples\n",
      "  Text length: min=35, max=394, mean=130.7\n",
      "\n",
      "Processing task3-TSR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR:  17%|█▋        | 2/12 [00:24<02:00, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ Unknown subject ZDN, defaulting to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "task3-TSR:  75%|███████▌  | 9/12 [02:40<00:53, 17.81s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:664] . unexpected pos 960 vs 854",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:967\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 967\u001b[0m     _save(\n\u001b[0;32m    968\u001b[0m         obj,\n\u001b[0;32m    969\u001b[0m         opened_zipfile,\n\u001b[0;32m    970\u001b[0m         pickle_module,\n\u001b[0;32m    971\u001b[0m         pickle_protocol,\n\u001b[0;32m    972\u001b[0m         _disable_byteorder_record,\n\u001b[0;32m    973\u001b[0m     )\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:1268\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m-> 1268\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(name, storage, num_bytes)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:863] . PytorchStreamWriter failed writing file data/0: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stats\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Process EEG-to-Text data\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m e2t_stats \u001b[38;5;241m=\u001b[39m process_e2t_data(all_data, OUTPUT_DIR_E2T)\n",
      "Cell \u001b[1;32mIn[5], line 67\u001b[0m, in \u001b[0;36mprocess_e2t_data\u001b[1;34m(all_data, output_dir)\u001b[0m\n\u001b[0;32m     64\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_s\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msent_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     65\u001b[0m pt_path \u001b[38;5;241m=\u001b[39m split_dir \u001b[38;5;241m/\u001b[39m filename\n\u001b[1;32m---> 67\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m'\u001b[39m: eeg_tensor,\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: content,\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual_length\u001b[39m\u001b[38;5;124m'\u001b[39m: actual_length,\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m: subject_id,\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence_idx\u001b[39m\u001b[38;5;124m'\u001b[39m: sent_idx,\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: task_name\n\u001b[0;32m     74\u001b[0m }, pt_path)\n\u001b[0;32m     76\u001b[0m sample_counts[split] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     77\u001b[0m text_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(content))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:966\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[0;32m    963\u001b[0m     f \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(f)\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 966\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    967\u001b[0m         _save(\n\u001b[0;32m    968\u001b[0m             obj,\n\u001b[0;32m    969\u001b[0m             opened_zipfile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    972\u001b[0m             _disable_byteorder_record,\n\u001b[0;32m    973\u001b[0m         )\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:798\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 798\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_like\u001b[38;5;241m.\u001b[39mwrite_end_of_file()\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:664] . unexpected pos 960 vs 854"
     ]
    }
   ],
   "source": [
    "\n",
    "# ## 6. Process EEG-to-Text Data\n",
    "\n",
    "# %%\n",
    "def process_e2t_data(all_data: Dict, output_dir: Path):\n",
    "    \"\"\"\n",
    "    Process all pickle data for EEG-to-Text decoding.\n",
    "    \n",
    "    Creates folder structure:\n",
    "    output_dir/\n",
    "    ├── task1-SR/\n",
    "    │   ├── train/\n",
    "    │   │   ├── ZAB_s0.pt\n",
    "    │   │   └── ...\n",
    "    │   ├── val/\n",
    "    │   └── test/\n",
    "    ├── task2-NR/\n",
    "    │   └── ...\n",
    "    └── task3-TSR/\n",
    "        └── ...\n",
    "    \n",
    "    Each .pt file contains:\n",
    "        - eeg: (channels, time) preprocessed EEG\n",
    "        - text: sentence content\n",
    "        - actual_length: original EEG length before padding\n",
    "        - subject: subject ID\n",
    "        - task: task name\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EEG-TO-TEXT PREPROCESSING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    stats = defaultdict(lambda: defaultdict(int))\n",
    "    \n",
    "    for task_name, task_data in all_data.items():\n",
    "        print(f\"\\nProcessing {task_name}...\")\n",
    "        \n",
    "        # Create output directories\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_dir = output_dir / task_name / split\n",
    "            split_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        sample_counts = {'train': 0, 'val': 0, 'test': 0}\n",
    "        text_lengths = []\n",
    "        \n",
    "        for subject_id, sentences in tqdm(task_data.items(), desc=task_name):\n",
    "            split = get_subject_split(subject_id)\n",
    "            split_dir = output_dir / task_name / split\n",
    "            \n",
    "            for sent_idx, sent in enumerate(sentences):\n",
    "                if sent is None:\n",
    "                    continue\n",
    "                \n",
    "                raw_eeg = sent['sentence_level_EEG']['rawData']\n",
    "                content = sent.get('content', '')\n",
    "                \n",
    "                # Skip if no text content\n",
    "                if not content or len(content.strip()) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Preprocess EEG\n",
    "                eeg_tensor, actual_length = preprocess_eeg_for_e2t(raw_eeg)\n",
    "                \n",
    "                # Save as .pt file\n",
    "                filename = f\"{task_name}_{subject_id}_s{sent_idx}.pt\"\n",
    "                pt_path = split_dir / filename\n",
    "                \n",
    "                torch.save({\n",
    "                    'eeg': eeg_tensor,\n",
    "                    'text': content,\n",
    "                    'actual_length': actual_length,\n",
    "                    'subject': subject_id,\n",
    "                    'sentence_idx': sent_idx,\n",
    "                    'task': task_name\n",
    "                }, pt_path)\n",
    "                \n",
    "                sample_counts[split] += 1\n",
    "                text_lengths.append(len(content))\n",
    "        \n",
    "        # Print stats for this task\n",
    "        print(f\"  {task_name} complete:\")\n",
    "        for split, count in sample_counts.items():\n",
    "            print(f\"    {split}: {count} samples\")\n",
    "            stats[task_name][split] = count\n",
    "        \n",
    "        if text_lengths:\n",
    "            print(f\"  Text length: min={min(text_lengths)}, max={max(text_lengths)}, mean={np.mean(text_lengths):.1f}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Process EEG-to-Text data\n",
    "e2t_stats = process_e2t_data(all_data, OUTPUT_DIR_E2T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 7. Create PyTorch Dataset Classes\n",
    "\n",
    "# %%\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EEGVJEPADataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for EEG-VJEPA pretraining.\n",
    "    \n",
    "    Loads preprocessed spectrogram .pt files.\n",
    "    Output shape: (1, T, C, F) - ready for 3D ViT\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str, split: str = 'train', tasks: List[str] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: Path to preprocessed_vjepa directory\n",
    "            split: 'train', 'val', or 'test'\n",
    "            tasks: List of tasks to include, e.g., ['task1-SR', 'task2-NR']\n",
    "                   If None, includes all available tasks\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.split = split\n",
    "        self.pt_files = []\n",
    "        \n",
    "        # Find all .pt files for specified tasks\n",
    "        if tasks is None:\n",
    "            tasks = ['task1-SR', 'task2-NR', 'task3-TSR']\n",
    "        \n",
    "        for task in tasks:\n",
    "            task_split_dir = self.data_dir / task / split\n",
    "            if task_split_dir.exists():\n",
    "                files = sorted(task_split_dir.glob('*.pt'))\n",
    "                self.pt_files.extend(files)\n",
    "        \n",
    "        print(f\"[{split}] Loaded {len(self.pt_files)} samples from {len(tasks)} tasks\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pt_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.load(self.pt_files[idx])\n",
    "        return data['spectrogram']  # (1, T, C, F)\n",
    "\n",
    "\n",
    "class EEGToTextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for EEG-to-Text decoding.\n",
    "    \n",
    "    Returns:\n",
    "        eeg: (channels, time) normalized EEG\n",
    "        text: sentence content string\n",
    "        actual_length: original EEG length before padding\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str, split: str = 'train', tasks: List[str] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: Path to preprocessed_e2t directory\n",
    "            split: 'train', 'val', or 'test'\n",
    "            tasks: List of tasks to include\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.split = split\n",
    "        self.pt_files = []\n",
    "        \n",
    "        if tasks is None:\n",
    "            tasks = ['task1-SR', 'task2-NR', 'task3-TSR']\n",
    "        \n",
    "        for task in tasks:\n",
    "            task_split_dir = self.data_dir / task / split\n",
    "            if task_split_dir.exists():\n",
    "                files = sorted(task_split_dir.glob('*.pt'))\n",
    "                self.pt_files.extend(files)\n",
    "        \n",
    "        print(f\"[{split}] Loaded {len(self.pt_files)} samples from {len(tasks)} tasks\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pt_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.load(self.pt_files[idx])\n",
    "        return {\n",
    "            'eeg': data['eeg'],\n",
    "            'text': data['text'],\n",
    "            'actual_length': data['actual_length'],\n",
    "            'subject': data['subject']\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57170ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VALIDATION\n",
      "============================================================\n",
      "\n",
      "EEG-VJEPA Preprocessed Data:\n",
      "  task1-SR/train: 40443 samples, shape=torch.Size([1, 29, 105, 33])\n",
      "  task1-SR/val: 3116 samples, shape=torch.Size([1, 29, 105, 33])\n",
      "  task1-SR/test: 3468 samples, shape=torch.Size([1, 29, 105, 33])\n",
      "  task2-NR/train: 39311 samples, shape=torch.Size([1, 29, 105, 33])\n",
      "  task2-NR/val: 2840 samples, shape=torch.Size([1, 29, 105, 33])\n",
      "  task2-NR/test: 3510 samples, shape=torch.Size([1, 29, 105, 33])\n",
      "  task3-TSR/train: 31616 samples, shape=torch.Size([1, 29, 105, 33])\n",
      "  task3-TSR/val: 2739 samples, shape=torch.Size([1, 29, 105, 33])\n",
      "  task3-TSR/test: 1493 samples, shape=torch.Size([1, 29, 105, 33])\n",
      "\n",
      "EEG-to-Text Preprocessed Data:\n",
      "  task1-SR/train: 3758 samples, EEG shape=torch.Size([105, 8000])\n",
      "    Example text: \"Presents a good case while failing to provide a re...\"\n",
      "  task1-SR/val: 386 samples, EEG shape=torch.Size([105, 8000])\n",
      "    Example text: \"Presents a good case while failing to provide a re...\"\n",
      "  task1-SR/test: 393 samples, EEG shape=torch.Size([105, 8000])\n",
      "    Example text: \"Presents a good case while failing to provide a re...\"\n",
      "  task2-NR/train: 2822 samples, EEG shape=torch.Size([105, 8000])\n",
      "    Example text: \"With his interest in race cars, he formed a second...\"\n",
      "  task2-NR/val: 287 samples, EEG shape=torch.Size([105, 8000])\n",
      "    Example text: \"With his interest in race cars, he formed a second...\"\n",
      "  task2-NR/test: 247 samples, EEG shape=torch.Size([105, 8000])\n",
      "    Example text: \"With his interest in race cars, he formed a second...\"\n",
      "  task3-TSR/train: 3856 samples, EEG shape=torch.Size([105, 8000])\n",
      "    Example text: \"Dole was twice decorated for heroic achievement, r...\"\n",
      "  task3-TSR/val: 404 samples, EEG shape=torch.Size([105, 8000])\n",
      "    Example text: \"He won the Gold Medal of the Royal Astronomical So...\"\n",
      "  task3-TSR/test: 317 samples, EEG shape=torch.Size([105, 8000])\n",
      "    Example text: \"He won the Gold Medal of the Royal Astronomical So...\"\n",
      "\n",
      "Testing Dataset Classes:\n",
      "[train] Loaded 111370 samples from 3 tasks\n",
      "  EEGVJEPADataset: ✓ (111370 samples, shape=torch.Size([1, 29, 105, 33]))\n",
      "[train] Loaded 10436 samples from 3 tasks\n",
      "  EEGToTextDataset: ✓ (10436 samples)\n",
      "    EEG shape: torch.Size([105, 8000])\n",
      "    Text: \"Presents a good case while failing to provide a re...\"\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 8. Validation & Statistics\n",
    "\n",
    "# %%\n",
    "def validate_preprocessing():\n",
    "    \"\"\"Validate the preprocessed data.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"VALIDATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check EEG-VJEPA data\n",
    "    print(\"\\nEEG-VJEPA Preprocessed Data:\")\n",
    "    for task in ['task1-SR', 'task2-NR', 'task3-TSR']:\n",
    "        task_dir = OUTPUT_DIR_VJEPA / task\n",
    "        if task_dir.exists():\n",
    "            for split in ['train', 'val', 'test']:\n",
    "                split_dir = task_dir / split\n",
    "                if split_dir.exists():\n",
    "                    count = len(list(split_dir.glob('*.pt')))\n",
    "                    if count > 0:\n",
    "                        # Load one sample to check shape\n",
    "                        sample_file = list(split_dir.glob('*.pt'))[0]\n",
    "                        sample = torch.load(sample_file)\n",
    "                        shape = sample['spectrogram'].shape\n",
    "                        print(f\"  {task}/{split}: {count} samples, shape={shape}\")\n",
    "    \n",
    "    # Check EEG-to-Text data\n",
    "    print(\"\\nEEG-to-Text Preprocessed Data:\")\n",
    "    for task in ['task1-SR', 'task2-NR', 'task3-TSR']:\n",
    "        task_dir = OUTPUT_DIR_E2T / task\n",
    "        if task_dir.exists():\n",
    "            for split in ['train', 'val', 'test']:\n",
    "                split_dir = task_dir / split\n",
    "                if split_dir.exists():\n",
    "                    count = len(list(split_dir.glob('*.pt')))\n",
    "                    if count > 0:\n",
    "                        # Load one sample to check\n",
    "                        sample_file = list(split_dir.glob('*.pt'))[0]\n",
    "                        sample = torch.load(sample_file)\n",
    "                        shape = sample['eeg'].shape\n",
    "                        text_preview = sample['text'][:50] + \"...\" if len(sample['text']) > 50 else sample['text']\n",
    "                        print(f\"  {task}/{split}: {count} samples, EEG shape={shape}\")\n",
    "                        print(f\"    Example text: \\\"{text_preview}\\\"\")\n",
    "    \n",
    "    # Test dataset classes\n",
    "    print(\"\\nTesting Dataset Classes:\")\n",
    "    try:\n",
    "        vjepa_ds = EEGVJEPADataset(OUTPUT_DIR_VJEPA, split='train')\n",
    "        if len(vjepa_ds) > 0:\n",
    "            sample = vjepa_ds[0]\n",
    "            print(f\"  EEGVJEPADataset: ✓ ({len(vjepa_ds)} samples, shape={sample.shape})\")\n",
    "    except Exception as e:\n",
    "        print(f\"  EEGVJEPADataset: ✗ ({e})\")\n",
    "    \n",
    "    try:\n",
    "        e2t_ds = EEGToTextDataset(OUTPUT_DIR_E2T, split='train')\n",
    "        if len(e2t_ds) > 0:\n",
    "            sample = e2t_ds[0]\n",
    "            print(f\"  EEGToTextDataset: ✓ ({len(e2t_ds)} samples)\")\n",
    "            print(f\"    EEG shape: {sample['eeg'].shape}\")\n",
    "            print(f\"    Text: \\\"{sample['text'][:50]}...\\\"\")\n",
    "    except Exception as e:\n",
    "        print(f\"  EEGToTextDataset: ✗ ({e})\")\n",
    "\n",
    "# Run validation\n",
    "validate_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f9fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PREPROCESSING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Output Directories:\n",
      "  EEG-VJEPA: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\preprocessed_vjepa\n",
      "  EEG-to-Text: c:\\MSc Files\\MSc Project\\E2T-w-VJEPA\\e2t-cloned-amirhojati\\eeg-vjepa\\src\\datasets\\preprocessed_e2t\n",
      "\n",
      "Subject Splits:\n",
      "  Train (9 subjects): ['ZAB', 'ZDM', 'ZGW', 'ZJM', 'ZJN', 'ZJS', 'ZKB', 'ZKH', 'ZKW']\n",
      "  Val (1 subjects): ['ZMG']\n",
      "  Test (1 subjects): ['ZPH']\n",
      "\n",
      "EEG-VJEPA Parameters:\n",
      "  Time Window: 512 samples\n",
      "  Overlap: 50%\n",
      "  FFT Size: 64\n",
      "  Hop Length: 16\n",
      "  Output Shape: (1, T, C, F) for 3D ViT\n",
      "\n",
      "EEG-to-Text Parameters:\n",
      "  Max EEG Length: 8000\n",
      "  Channels: 105\n",
      "  Output Shape: (channels, time) + text\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 9. Summary\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Output Directories:\n",
    "  EEG-VJEPA: {OUTPUT_DIR_VJEPA}\n",
    "  EEG-to-Text: {OUTPUT_DIR_E2T}\n",
    "\n",
    "Subject Splits:\n",
    "  Train ({len(TRAIN_SUBJECTS)} subjects): {TRAIN_SUBJECTS}\n",
    "  Val ({len(VAL_SUBJECTS)} subjects): {VAL_SUBJECTS}\n",
    "  Test ({len(TEST_SUBJECTS)} subjects): {TEST_SUBJECTS}\n",
    "\n",
    "EEG-VJEPA Parameters:\n",
    "  Time Window: {TIME_WINDOW} samples\n",
    "  Overlap: {OVERLAP*100:.0f}%\n",
    "  FFT Size: {N_FFT}\n",
    "  Hop Length: {HOP_LENGTH}\n",
    "  Output Shape: (1, T, C, F) for 3D ViT\n",
    "\n",
    "EEG-to-Text Parameters:\n",
    "  Max EEG Length: {MAX_EEG_LENGTH}\n",
    "  Channels: {TARGET_CHANNELS}\n",
    "  Output Shape: (channels, time) + text\n",
    "\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51d4b357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load EEG-VJEPA dataset\n",
    "# from preprocess_spector import EEGVJEPADataset\n",
    "# train_ds = EEGVJEPADataset('{OUTPUT_DIR_VJEPA}', split='train')\n",
    "# val_ds = EEGVJEPADataset('{OUTPUT_DIR_VJEPA}', split='val')\n",
    "\n",
    "# # Load EEG-to-Text dataset\n",
    "# from preprocess_spector import EEGToTextDataset\n",
    "# train_ds = EEGToTextDataset('{OUTPUT_DIR_E2T}', split='train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
